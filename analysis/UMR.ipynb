{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dd1cc2-d891-47a0-b879-cee75de8a34b",
   "metadata": {},
   "source": [
    "# UMR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1935e-6a8e-4d95-89cd-b44368b035e8",
   "metadata": {},
   "source": [
    "## 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8adf70ef-9af5-4a0d-95c1-db3e05dc31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95977f-7fdd-43c6-9a30-a06eed8e65fd",
   "metadata": {},
   "source": [
    "## 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a40a263-46e3-409b-9742-946bb4ee1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('2023-01-01')\n",
    "end_date = pd.to_datetime('2023-12-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af1554-0b45-4cba-ac14-dd6893c87dc5",
   "metadata": {},
   "source": [
    "### 日线数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69631ecf-582c-48d7-bcec-336b5a7d0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_1d = feather.read_dataframe('../data/StockPriceK1d_20241231.feather')\n",
    "price_1d = price_1d[(price_1d['date'] >= start_date) & (price_1d['date'] <= end_date)]\n",
    "price_1d = price_1d.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734e996-ebca-4eb0-9822-0f6cd409cdef",
   "metadata": {},
   "source": [
    "### 指数数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c8cbc4-6716-49a5-97b3-80d4096fc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs500 = feather.read_dataframe('../data/IndexPriceK1m_000905.feather')\n",
    "hs500['ret_index'] = hs500['close'] / hs500['close'].shift(1) - 1\n",
    "\n",
    "hs500['date'] = pd.to_datetime(hs500['date'], format='ISO8601')\n",
    "hs500 = hs500[(hs500['date'] >= start_date) & (hs500['date'] <= end_date)]\n",
    "hs500 = hs500.set_index('date')\n",
    "\n",
    "trade_time = hs500['time']\n",
    "map_trade_time = {t: t - 100 for t in trade_time}\n",
    "map_trade_time[100000] = 95900\n",
    "map_trade_time[110000] = 105900\n",
    "map_trade_time[140000] = 135900\n",
    "map_trade_time[150000] = 145900\n",
    "hs500['time'] = hs500['time'].apply(map_trade_time.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7fefd-e298-4679-bad4-32fcfa3eef14",
   "metadata": {},
   "source": [
    "### 分钟线测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6cf7ff-007e-45de-b447-e12194689049",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.to_datetime('2023-01-03')\n",
    "\n",
    "def price_1m_read(date:np.datetime64):\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    price_1m = feather.read_dataframe(f'../data/StockPriceK1m/{year}/StockPriceK1m_{date_str}.feather')\n",
    "    price_1m['date'] = pd.to_datetime(price_1m['date'], format='ISO8601')\n",
    "    \n",
    "    price_1m = pd.merge(\n",
    "        price_1m[['date', 'time', 'issue', 'high', 'low', 'close']],\n",
    "        price_1d.loc[date, ['issue', 'preclose']],\n",
    "        on='issue',\n",
    "        how='left'\n",
    "    )\n",
    "    price_1m['close_prev'] = (\n",
    "        price_1m\n",
    "            .groupby('issue')['close']\n",
    "            .shift(1).fillna(price_1m['preclose'])\n",
    "    )\n",
    "    price_1m['ret'] = price_1m['close'] / price_1m['close_prev'] - 1\n",
    "    \n",
    "    price_1m = pd.merge(\n",
    "        price_1m,\n",
    "        hs500.loc[date, ['time', 'ret_index']],\n",
    "        on='time',\n",
    "        how='left'\n",
    "    )\n",
    "    price_1m['excess'] = price_1m['ret'] - price_1m['ret_index']\n",
    "    # price_1m['excess'] = price_1m['ret']\n",
    "    \n",
    "    return price_1m\n",
    "\n",
    "price_1m = price_1m_read(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274e5d4-237c-43f4-a320-885fbae66cb5",
   "metadata": {},
   "source": [
    "## 计算风险指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf061d-687e-4b16-b631-5fe33e77d1b8",
   "metadata": {},
   "source": [
    "### 计算调整后风险系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fef1a34-a52e-4450-b2e9-65e5a590fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_calc(r:pd.Series, d:int=10):\n",
    "    return r.rolling(d, min_periods=1).mean() - r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381956c-7ad7-4f98-9fd2-84fd62212048",
   "metadata": {},
   "source": [
    "### 真实波动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684d45e3-03a8-416d-9d00-2692051c9afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_calc(price_1m:pd.DataFrame):\n",
    "    tr = price_1m.copy()\n",
    "    tr['tr1'] = tr['high'] - tr['low']\n",
    "    tr['tr2'] = np.abs(tr['high'] - tr['close_prev'])\n",
    "    tr['tr3'] = np.abs(tr['low'] - tr['close_prev'])\n",
    "    tr['r'] = tr[['tr1', 'tr2', 'tr3']].max(axis=1) / tr['close_prev']\n",
    "    return tr[['date', 'time', 'issue', 'r']]\n",
    "tr = tr_calc(price_1m)\n",
    "tr['risk'] = tr.groupby('issue')['r'].transform(risk_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930721b8-d578-425b-a59b-242d2538df65",
   "metadata": {},
   "source": [
    "## 计算动量反转因子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beea9f5-f2e5-45eb-a612-9bfeb2c2a002",
   "metadata": {},
   "source": [
    "### 计算单日内反转因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb01b0a-374f-4102-a056-9ec8c8d6d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_calc(date:np.datetime64, price_1m:pd.DataFrame, risk:pd.DataFrame=None, m:int=60, decay:bool=True):\n",
    "    m = 60\n",
    "    H = m / 2\n",
    "    weight = 2 ** ((np.arange(m) - m) / H)\n",
    "    weight = weight / weight.sum()\n",
    "\n",
    "    ret_risk = price_1m[['time', 'issue', 'excess']].copy()\n",
    "    if risk is None:\n",
    "        ret_risk['risk'] = -1\n",
    "    else:\n",
    "        ret_risk = pd.merge(\n",
    "            ret_risk,\n",
    "            risk[['time', 'issue', 'risk']],\n",
    "            on=['time', 'issue'],\n",
    "            how='left'\n",
    "        ).sort_values(['issue', 'time'])\n",
    "    weight = np.tile(weight, len(ret_risk['issue'].unique()))\n",
    "    \n",
    "    start_time = np.array([93000, 103000, 130000, 135400])\n",
    "    end_time = np.array([102900, 112900, 135900, 145300])\n",
    "    rev = None\n",
    "    for st, et in zip(start_time, end_time):\n",
    "        rr = ret_risk[(ret_risk['time'] >= st) & (ret_risk['time'] <= et)].copy()\n",
    "        if not decay:\n",
    "            rr['weight'] = 1\n",
    "        else:\n",
    "            rr['weight'] = weight\n",
    "\n",
    "        rr['rev'] = rr['weight'] * rr['risk'] * rr['excess']\n",
    "        rev_time = (\n",
    "            rr\n",
    "                .groupby('issue')['rev']\n",
    "                .sum().reset_index()\n",
    "        )\n",
    "        rev_time['time'] = et\n",
    "        rev = pd.concat([rev, rev_time])\n",
    "    rev['date'] = date\n",
    "    rev = rev.sort_values(['issue', 'time']).reset_index(drop=True)\n",
    "    return rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c35eff-fc23-4c9c-931f-9e853cd861a3",
   "metadata": {},
   "source": [
    "### 性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc3f30b-f772-4587-b4c5-b0fad2b8e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f price_1m_read price_1m_read(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "148a0984-d76d-479e-a4d1-24d9e8cadfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f tr_calc tr_calc(price_1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281ea280-a623-4b41-95f2-b0fa46e658b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f rev_calc rev_calc(date, price_1m, tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823e357-6cd3-492c-977f-123f9c0b7465",
   "metadata": {},
   "source": [
    "### 遍历所有交易日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56676f1f-293d-4e1b-adb7-039480d436ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bda8a8011aa4d208705c08f4230f165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trade_date = price_1d.index.sort_values().unique()\n",
    "label = 'tr'\n",
    "risk_func = tr_calc\n",
    "risk_prev = None\n",
    "os.makedirs(f'../data/factor_rev/{label}_rev/', exist_ok=True)\n",
    "for date in tqdm(trade_date):\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    os.makedirs(f'../data/factor_rev/{label}_rev/{year}/', exist_ok=True)\n",
    "    price_1m = price_1m_read(date)\n",
    "    \n",
    "    risk = risk_func(price_1m)\n",
    "    risk_2d = pd.concat([risk_prev, risk])\n",
    "    risk_prev = risk\n",
    "    risk_2d['risk'] = risk_2d.groupby('issue')['r'].transform(risk_calc)\n",
    "    risk = risk_2d[risk_2d['date'] == date]\n",
    "    \n",
    "    rev = rev_calc(date, price_1m, risk=risk, decay=True)\n",
    "    feather.write_dataframe(rev, f'../data/factor_rev/{label}_rev/{year}/{label}_rev_{date_str}.feather')\n",
    "    del price_1m, risk, rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de6ea2d1-966a-437b-9f17-7be3b56592a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_calc(date:pd.Series, time:pd.Series):\n",
    "    hh = time // 10000\n",
    "    mm = (time % 10000) // 100\n",
    "    ss = time % 100\n",
    "    timedelta = pd.to_timedelta(hh, 'h') + pd.to_timedelta(mm, 'm') + pd.to_timedelta(ss, 's')\n",
    "    datetime = date + timedelta\n",
    "    return datetime\n",
    "\n",
    "rev = None\n",
    "for date in trade_date:\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    rev_daily = feather.read_dataframe(f'../data/factor_rev/{label}_rev/{year}/{label}_rev_{date_str}.feather')\n",
    "    rev = pd.concat([rev, rev_daily])\n",
    "rev['datetime'] = datetime_calc(rev['date'], rev['time'])\n",
    "rev = rev.reset_index(drop=True)\n",
    "feather.write_dataframe(rev, f'../data/factor_rev/{label}_rev/{label}_rev.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
